### 웹 크롤링 ###

#! 1. 웹 크롤링(web crawling)
# : 웹 페이지를 체계적으로 탐색하여 원하는 데이터를 추출하는 행위
# : 웹 크롤러 - 크롤링 수행하는 프로그램

#! 2. 웹 크롤링 목적
# 2-1. 검색 엔진 최적화(SEO)
# : 웹 크롤러는 검색 엔진에서 웹 페이지의 내용을 인덱싱(추출)하기 위해 사용
# 2-2. 데이터 수집
# : 특정 웹 사이트에서 정보를 수집할 경우 사용
# 2-3. 시장 조사, 콘텐츠 모니터링 

#! 3. 파이썬을 이용한 웹 크롤링
# : 파이썬 외부 라이브러리의 지원(BeautifulSoup, Scrapy...)
# : 확장성 - 다양한 데이터 처리 및 분석 도구와의 연동이 용이

#! 4. HTTP의 기본 이해
# HTTP(HyperText Trasfer Protocol)
# : 웹에서 데이터를 주고받는 규약

# 4-1. HTTP와 웹 크롤링의 관계
# : 웹 크롤링 시 웹 서버에게 정보를 요청하고 그 응답을 받아오는 과정에서 HTTP를 사용

# 4-2. HTTP 요청과 응답
# 요청(Request): 웹 브라우저(클로러)가 서버에게 정보나 서비스를 요청하는 메시지
# 응답(Response): 서버가 요청을 처리한 후 반환하는 메시지

# 4-3. HTTP메서드
# GET: 웹페이지의 내용을 조회할 때 사용, 웹 크롤링에서 가장 기본적인 요청 방식
# POST: 서버에 데이터를 보낼 때 사용

# 4-4. HTTP 상태 코드(크롤링 중 발생할 수 있는 상태)
# 200 OK: 성공적으로 응답 받았음.(크롤링 대상 데이터를 가져오기 가능)
# 403 Forbidden: 접근 권한이 없음.(로봇 차단 정책 등으로 크롤링 제한)
# 404 Not Found
# : 요청한 URL에 해당하는 페이지가 없음.(링크가 끊긴 페이지 참조 시 발생) 

#! User-Agent
# : 웹 브라우저나 기타 클라이언트가 서버에게 자신의 신분을 알리기 위해
# : HTTP 요청 헤더에 포함시키는 문자열

#! robots.txt
# : 웹 사이트의 어느 부분을 수집하거나 수집하지 않아야 하는지에 대한 지침을 제공

# User-agent: [user-agent name]
# Disallow: [URL string not to be fetched]
# Allow: [URL string to be fetched]

# [예시]
# User-agent: * (*는 모든 크롤러에게 적용됨)
# Disallow: /private/
# Disallow: /temp/
